[toc]

# 减少`CPU`上下文的切换

## 什么是上下文切换

CPU将当前线程的信息保存到内存中，且从内存中获取下一个得到时间片的线程信息。

线程信息包括不限于`寄存器的值`等。

## 引起线程上下文切换的原因

- 当前正在执行的线程完成，CPU正常调度下一个线程。

- 当前正在执行的线程遇到I/O等阻塞操作，调度器挂起该线程，继续调度下一个线程。

  > 比如打日志，在代码`org.hc.learning.thread.queue.boundebuffer.BoundBufferTest`中，在20000个任务下，4个线程的情况下，JDK阻塞队列ArrayBlockingQueue效率远远高于自己实现的SyncBufferImpl与ConditionBufferImpl。
  >
  > 但移除打印日志后，SyncBufferImpl效率最高。
  >
  > 之所以SyncBufferImpl效率最高，个人认为是在短时间内锁的获取与释放较少，允许线程在时间片范围内完成更多的任务，最终引起的上下文切换较少。

- 多个线程抢占锁资源，当前线程未得到锁，被调度器挂起，继续调度下一个线程。

- 调用`sleep()`等方法让出CPU。

- 硬件中断。

# 自旋锁的使用场景

在使用自旋锁时，或者说我们的代码中存在类似死循环之类的代码时，将大量的耗费CPU资源。但在高并发情况下，如果直接使用阻塞或唤醒线程的操作，就需要不断地挂起或恢复线程，产生大量地**上下文切换**，反而得不偿失。

毕竟自旋时，在大部分时候是相当短暂地。比起上下文切换耗费的资源，自旋所耗费的不值一提。

# IllegalMonitorStateException

有一段代码一直在出现这个`Exception`，先看代码：

``` java
synchronized (currentState) {
    if (currentState%3 != state) {
        log.debug(Thread.currentThread().getName() + " wait {}", System.identityHashCode(currentState));
        try {
            currentState.wait();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    } else {
        System.out.print(Thread.currentThread().getName() + (currentState%size + 1 == size? "\n": ""));
        currentState++;
        log.debug(Thread.currentThread().getName() + " notifyAll, {}", System.identityHashCode(currentState));
        currentState.notifyAll();
    }
}
```

其中`currentState`是一个`Integer`类型的变量，用于记录当前的状态。

当另一个线程调用这段的代码的`currentState.notifyAll()`时就会抛出`illegalMonitorStateException`。

研究很久之后觉得百度一下这个`illegalMonitorStateException`到底什么意思？

- **refer**
- [关于IllegalMonitorStateException异常的解释](https://blog.csdn.net/wangshuang1631/article/details/53815519)

> 抛出该异常表明某一线程已经试图等待对象的监视器，或者试图通知其他正在等待对象的监视器，然而本身没有指定的监视器的线程。

个人理解，就是当前线程并没有获得锁却调用了该锁的`wait()`、`notify()`、`notifyAll()`等方法。

但明明就在代码块之中。

这时我想起`Integer`类型在使用`=`、`++`等会返回一个新的`Integer`对象。

**归根到底，这是对自动封装理解不到位导致的线程安全问题**

# ETL项目优化过程

## **需求背景**

某地将该地人脸数据及照片从`云平台`上抽取下来，经过`ETL工具`项目转发到`RabbitMq`。

原实现过程为云平台主动推送给`ETL工具`的接口，现在需要修改为`ETL工具`主动抽取云平台数据及照片。

## 时序图

- **原系统时序图**

``` sequence
participant ETL.web
participant ETL.BlockingQueue
participant cloud
participant ETL.Job
participant 图片服务器

cloud - ETL.web : 人脸数据 (Http request)
ETL.web -- cloud : 接收成功 (Http response)
ETL.web - ETL.BlockingQueue : 缓存人脸数据
ETL.Job - ETL.BlockingQueue : 异步抽取数据
ETL.BlockingQueue -- ETL.Job : 返回
ETL.Job - ETL.Job : 处理数据
ETL.Job - 图片库 : 根据url下载图片
图片库 -- ETL.Job : successful
ETL.Job - 图片服务器 : 上传人脸图片到图片服务器
图片服务器 -- ETL.Job : successful
ETL.Job - RabbitMQ : 上传人脸信息



```

在该架构下，`Job`线程需要执行从阻塞队列中抽取人脸数据、转换、上传。由于云平台主动推送人脸数据，从云平台获取数据与`Job`业务流程天然分离，不会由于转换、或者上传业务耗时太久而影响了抽取。

其中从图片库下载人脸照片、将人脸照片上传到图片服务器均在`translate`环节完成，因此`translate`是最耗费时间的环节。

- **第一次修改后的时序图**

  云平台推送人脸数据修改为主动访问人脸接口。

  ``` sequence
  participant ETL.extract
  participant ETL.translate
  participant cloud
  ETL.extract - ETL.extract : 记录当前时间
  ETL.extract - ETL.extract : 休眠1second
  ETL.extract - ETL.extract : 更新时间记录, 同时获取一个时间区间
  ETL.extract - cloud : 根据时间区间start、end查询人脸信息
  cloud -- ETL.extract : 返回人脸信息
  ETL.extract - ETL.translate : 人脸信息
  ETL.translate - ETL.translate : 处理人脸信息
  ETL.translate - 图片库 : download
  图片库 -- ETL.translate : byte
  ETL.translate - 图片服务器 : byte
  图片服务器 -- ETL.translate : url
  ETL.translate - ETL.load : 人脸信息
  ETL.load - RabbitMq : 人脸信息
  
  ```

  最初通过休眠来计算上次查询的时刻(`lastAccess`)与当前时间，以获得一个时间区间。同时这个步骤放在`extract`环节中，结果导致上传到`RabbitMQ`存在严重的滞后。

  > 用一个`lastAccess`变量来记录上次查询时间。

  为什么会存在如此严重的滞后呢？这个`Job`代表一个线程，第一次抽取后经过`translate`、`load`之后，进行第二次抽取。

  第二次抽取时，当前时间距离`lastAccess`的差距需要加上`translate`、`load`所耗费的时间。**这是在最初设计时忽略掉的**，低估了转换、上传消耗的时间。

  如此一来，查询的时间区间远远大于预计的时间，导致查询的数据量增多，从而导致转换、上传的耗费时间更多，结果又令查询的时间区间增大，恶性循环，致使延迟问题越来越严重。

- **第二次修改后的时序图**

  经过对延迟问题的分析与对原程序的参考，决定将`Job`与真正的抽取任务分离，同时增加`BlockingQueue`缓存抽取得到的数据。 

  相当于我们只是将`Job`作为一个消费者，而另外构建一个生产者。分离之后，我们便可以开辟一个或者多个线程进行抽取，而不受到转换与上传的影响。另外修改计算时间的方式，取消`Thread.sleep(long)`，而是在上传查询时间的基础上增加固定的值。当时间区间超过当前时间后进行自旋，减小由于阻塞带来的上下文切换，进一步减小延迟。

  ``` sequence
  participant ETL.extract
  participant ETL.Job
  participant BlockingQueue
  participant cloud
  
  ETL.extract - cloud : 查询
  cloud -- ETL.extract : 返回
  ETL.extract - BlockingQueue : 缓存数据
  ETL.Job - BlockingQueue : 读取数据
  ETL.Job - ETL.Job : 处理数据
  ETL.Job - 图片库 : 下载图片
  图片库 -- ETL.Job : byte
  ETL.Job - 图片服务器 : byte
  图片服务器 -- ETL.Job : url
  ETL.Job - RabbitMq : 数据
  
  ```

  另外，对阻塞队列大小设置的比较大，而抽取线程在每次抽取完之后并没有进行短时间的休眠，导致阻塞队列往往是抽取线程一直在存取或`Job`一直在读取数据（结合`活锁`概念理解）。最终结果就是尽管抽取的数据并不存在延迟，但是将数据上传到`RabbitMq`存在延迟。

  所以有时候在处理这种`I/O密集型`任务的时候，一定要考虑消费端的能力以确定合适的缓存大小或者说是分块大小。